{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a6cc55",
   "metadata": {},
   "source": [
    "# Notebook for creating figures of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf05ff",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e7d29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from Dataset.dataset import TranslationDataset, normalize, esawc_to_image\n",
    "from Models.classifiers import *\n",
    "\n",
    "with open(\"local_config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "data_root = Path(config[\"data_root\"])\n",
    "\n",
    "# For results figure\n",
    "countries = [\n",
    "    \"United_Kingdom\",\n",
    "    \"Portugal\", \n",
    "    \"Czech_Republic\", \n",
    "    \"Sweden\", \n",
    "]\n",
    "regions = [\n",
    "    \"England\",\n",
    "    \"Portugal\",\n",
    "    \"Czech_Republic\",\n",
    "    \"Stockholms_Laen\",\n",
    "]\n",
    "idxs = [0, 229, 11, 0]\n",
    "\n",
    "# For motivation figure\n",
    "# countries = [\"Croatia\"]\n",
    "# regions = [\"Croatia\"]\n",
    "# idxs = [12]\n",
    "\n",
    "mins = TranslationDataset.mins\n",
    "maxs = TranslationDataset.maxs\n",
    "visualization = [2,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da9641",
   "metadata": {},
   "source": [
    "## Dataset samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a9cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(countries)):\n",
    "    \n",
    "    country, region, idx = countries[i], regions[i], idxs[i]\n",
    "    \n",
    "    s2 = torch.load(os.path.join(data_root, \"Images\", \"Sentinel-2\", \"2018\", country, f\"{region}{idx}.pt\"))\n",
    "    s2 = normalize(s2, mins, maxs)\n",
    "    s2 = s2[visualization].permute(1,2,0).numpy()\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(s2 * 1.5)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    l8 = torch.load(os.path.join(data_root, \"Images\", \"Landsat8\", \"2018\", country, f\"{region}{idx}.pt\"))\n",
    "    l8 = normalize(l8, mins, maxs)\n",
    "    l8 = l8[visualization].permute(1,2,0).numpy()\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(l8)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    l8_pan = torch.load(os.path.join(data_root, \"Images\", \"Landsat8-Panchro\", \"2018\", country, f\"{region}{idx}.pt\"))\n",
    "    l8_pan = l8_pan.squeeze()\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(l8_pan, cmap=\"binary_r\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e768a219",
   "metadata": {},
   "source": [
    "## Translation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c4a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(countries)):\n",
    "    \n",
    "    country, region, idx = countries[i], regions[i], idxs[i]\n",
    "    \n",
    "    img = torch.load(os.path.join(data_root, \"Images\", \"Landsat8-Translated\", \"Diffusion_EMA_2025-10-05_23-31-54_0.4\", \"2018\", country, f\"{region}{idx}.pt\"))\n",
    "    img += torch.load(os.path.join(data_root, \"Images\", \"Landsat8-Translated\", \"Diffusion_EMA_2025-10-05_23-31-54_0.4_v2\", \"2018\", country, f\"{region}{idx}.pt\"))\n",
    "    img += torch.load(os.path.join(data_root, \"Images\", \"Landsat8-Translated\", \"Diffusion_EMA_2025-10-05_23-31-54_0.4_v3\", \"2018\", country, f\"{region}{idx}.pt\"))\n",
    "    # ls8 += torch.load(os.path.join(data_root, \"Images\", \"Landsat8-Translated\", \"Diffusion_EMA_2025-10-05_23-31-54_0.4_v4\", \"2018\", country, f\"{region}{idx}.pt\"))\n",
    "    # ls8 += torch.load(os.path.join(data_root, \"Images\", \"Landsat8-Translated\", \"Diffusion_EMA_2025-10-05_23-31-54_0.4_v5\", \"2018\", country, f\"{region}{idx}.pt\"))\n",
    "    img /= 3\n",
    "    img = img[visualization].permute(1,2,0).numpy()\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(img * 1.5)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb8632",
   "metadata": {},
   "source": [
    "## Land cover classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847060cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import GaussianBlur\n",
    "\n",
    "classifier = DeepLabV3_SMP(4, 9, \"resnet34\")\n",
    "classifier.load_state_dict(torch.load(\"Checkpoints/ClassifierDeepLabV3_2025-10-13_22-08-36/checkpoint.pt\"))\n",
    "classifier.eval()\n",
    "\n",
    "for i in range(len(countries)):\n",
    "    \n",
    "    country, region, idx = countries[i], regions[i], idxs[i]\n",
    "    \n",
    "    img = torch.load(os.path.join(data_root, \"Images\", \"Landsat8-Translated\", \"Diffusion_EMA_2025-10-05_23-31-54_0.4\", \"2018\", country, f\"{region}{idx}.pt\"))\n",
    "    img += torch.load(os.path.join(data_root, \"Images\", \"Landsat8-Translated\", \"Diffusion_EMA_2025-10-05_23-31-54_0.4_v2\", \"2018\", country, f\"{region}{idx}.pt\"))\n",
    "    img += torch.load(os.path.join(data_root, \"Images\", \"Landsat8-Translated\", \"Diffusion_EMA_2025-10-05_23-31-54_0.4_v3\", \"2018\", country, f\"{region}{idx}.pt\"))\n",
    "    img /= 3\n",
    "    with torch.inference_mode():\n",
    "        lc_hat = torch.argmax(classifier(img[None,:,:,:]).squeeze(), dim=0)\n",
    "    lc_hat = lc_hat.numpy()\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(esawc_to_image(lc_hat))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b643e",
   "metadata": {},
   "source": [
    "## SSIM/FID vs IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7cd8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "matplotlib.rcParams.update({'font.size': 22, 'font.family': 'serif'})\n",
    "matplotlib.rcParams.update({})\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "# Pansharpening + Regression\n",
    "plt.scatter(0.761, 32.0, s=100, c=\"palegreen\", edgecolors=\"k\", label=\"Bicubic + pansharpening\")\n",
    "plt.scatter(0.768, 33.8, s=100, c=\"limegreen\", edgecolors=\"k\", label=\"+ scale-only regression\")\n",
    "plt.scatter(0.764, 19.8, s=100, c=\"green\", edgecolors=\"k\", label=\"+ linear regression\")\n",
    "# DL methods\n",
    "plt.scatter(0.826, 35.9, s=100, c=\"aquamarine\", edgecolors=\"k\", label=\"UNet\")\n",
    "plt.scatter(0.846, 44.5, s=100, c=\"darkturquoise\", edgecolors=\"k\", label=\"+ SSIM loss\")\n",
    "plt.scatter(0.821, 35.1, s=100, c=\"dodgerblue\", edgecolors=\"k\", label=\"AUNet\")\n",
    "plt.scatter(0.832, 36.7, s=100, c=\"blue\", edgecolors=\"k\", label=\"+ SSIM loss\")\n",
    "plt.scatter(0.827, 35.1, s=100, c=\"mediumorchid\", edgecolors=\"k\", label=\"UNet Ensemble\")\n",
    "# Generative\n",
    "plt.scatter(0.732, 41.8, s=100, c=\"gold\", edgecolors=\"k\", label=\"Pix2Pix\")\n",
    "plt.scatter(0.723, 45.6, s=100, c=\"orange\", edgecolors=\"k\", label=\"Palette\")\n",
    "plt.scatter(0.806, 54.1, s=100, c=\"indianred\", edgecolors=\"k\", label=\"L8-S2 Diffusion\")\n",
    "plt.ylim([15,55])\n",
    "plt.xlabel(\"SSIM\")\n",
    "plt.ylabel(\"IoU in %\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "# Pansharpening + Regression\n",
    "plt.scatter(64.6, 32.0, s=100, c=\"palegreen\", edgecolors=\"k\", label=\"Bicubic + pansharpening\")\n",
    "plt.scatter(62.1, 33.8, s=100, c=\"limegreen\", edgecolors=\"k\", label=\"+ scale-only regression\")\n",
    "plt.scatter(69.2, 19.8, s=100, c=\"green\", edgecolors=\"k\", label=\"+ linear regression\")\n",
    "# DL methods\n",
    "plt.scatter(53.3, 35.9, s=100, c=\"aquamarine\", edgecolors=\"k\", label=\"UNet\")\n",
    "plt.scatter(51.3, 44.5, s=100, c=\"darkturquoise\", edgecolors=\"k\", label=\"+ SSIM loss\")\n",
    "plt.scatter(55.3, 35.1, s=100, c=\"dodgerblue\", edgecolors=\"k\", label=\"AUNet\")\n",
    "plt.scatter(51.9, 36.7, s=100, c=\"blue\", edgecolors=\"k\", label=\"+ SSIM loss\")\n",
    "plt.scatter(55.1, 35.1, s=100, c=\"mediumorchid\", edgecolors=\"k\", label=\"UNet Ensemble\")\n",
    "# Generative\n",
    "plt.scatter(29.7, 41.8, s=100, c=\"gold\", edgecolors=\"k\", label=\"Pix2Pix\")\n",
    "plt.scatter(46.9, 45.6, s=100, c=\"orange\", edgecolors=\"k\", label=\"Palette\")\n",
    "plt.scatter(22.5, 54.1, s=100, c=\"indianred\", edgecolors=\"k\", label=\"L8-S2 Diffusion\")\n",
    "plt.ylim([15,55])\n",
    "plt.xlabel(\"FID\")\n",
    "plt.ylabel(\"IoU in %\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
